{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyxno2zE+mvAmj/1EC6Kc4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ash-rulz/TextMining/blob/main/TextMiningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG\n",
        "This notebook implements a RAG pipeline for answering questions related to the first book in the Harry Potter series - \"Harry Potter and the Sorcer's Stone\".\n",
        "\n",
        "The whole process can be summarized as follows:\n",
        "1. **PDF splitter**: A PDF version of the book is parsed and split into smaller chunks.\n",
        "2. **Sentence embedding**: These chunks of information is transformed into sentence embeddings. The sentence embedder user for this is *sentence-transformers/all-MiniLM-L6-v2*.\n",
        "3. **Vector DB**: The embeddings are stored in vector DB. The vector DB used here is FAISS.\n",
        "4. **Generator**: A generator based on a LLM is created. The generator used here is *google/flan-t5-large*.\n",
        "5. **Retriever chain**: A retriever chain is then created. The input to a retriever chain will be a question. The question is converted into a sentence embedding which is then compared with the embedding in the vector DB. The k most similar documents are retrieved from the vector DB. These documents are passed as *context* in the custom made prompt template, along with the original question. This prompt is passed to the Generator to get the answer to the question.\n",
        "6. **Evaluation**: The whole RAG pipeline is evaluated using the RAGAS framework.\n",
        "7. **Improvements**: We try out different ways to improve the evaluation scores."
      ],
      "metadata": {
        "id": "vdl4CAbxIq0F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_DBvJjgf8ciZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U langchain pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the pdf to memory\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "pdfLoader = PyPDFLoader(\"Book.pdf\")\n",
        "documents = pdfLoader.load()"
      ],
      "metadata": {
        "id": "2ZmWiKq-8lb5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the file to chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100,\n",
        "    separators=['\\n\\n', '\\n', '(?=>\\. )', ' ', ''])\n",
        "docs = text_splitter.split_documents(documents)\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QI-BnYP876i",
        "outputId": "0177fdb9-e031-4231-d5ab-1ada32ae3c90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1189"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q sentence-transformers faiss-gpu"
      ],
      "metadata": {
        "id": "txOLgoaf9L8a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Store the documents in a vector store\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "model_path = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_path,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "#Create vector store\n",
        "from langchain.vectorstores import FAISS\n",
        "db = FAISS.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "jtlPJqUn9N0i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of documents retrieved from the vector DB for a question\n",
        "question = \"What is the name of Filch's cat?\"\n",
        "searchDocs = db.similarity_search_with_score(question)\n",
        "print(searchDocs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA3Qjr7T9xQY",
        "outputId": "828bba35-d77a-4dac-d35d-1d06d46d515c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Document(page_content=\"106Filch owned a cat called Mrs. Norris, a scrawny, dust-colored creature\\nwith bulging, lamp like eyes just like Filch's. She patrolled thecorridors alone. Break a rule in front of her, put just one toe out ofline, and she'd whisk off for Filch, who'd appear, wheezing, two secondslater. Filch knew the secret passageways of the school better thananyone (except perhaps the Weasley twins) and could pop up as suddenly\\nas any of the ghosts. The students all hated him, and it was the dearest\", metadata={'source': 'Book.pdf', 'page': 106}), 0.747094)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a generator\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,pipeline\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "model_name_flan = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_flan)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_flan)\n",
        "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer,max_new_tokens=200)\n",
        "llm = HuggingFacePipeline(\n",
        "    pipeline = pipe,\n",
        "    model_kwargs={\"temperature\": 0, \"max_length\": 1000000},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyej7Ao_Ff2c",
        "outputId": "998860a1-f38b-403e-9077-ff614c53d3e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evidence of hallucination by the T5 model\n",
        "question = \"What is the name of Filch's cat?\"\n",
        "llm_result = llm.invoke(question)\n",
        "llm_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uwyGN6HkFwQz",
        "outputId": "484f9c6d-ffff-4d23-e026-33e0e9b95b49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sam'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a retriever\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from operator import itemgetter\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "### CONTEXT\n",
        "{context}\n",
        "\n",
        "### QUESTION\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "base_retriever = db.as_retriever(search_kwargs={\"k\" : 3})\n",
        "retrieval_augmented_qa_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | base_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ],
      "metadata": {
        "id": "ZF1zrlOH-HtH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evidence of how the RAG improved the result\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "result['response']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "IUEKSeonGjky",
        "outputId": "aa3527a9-7a0b-4706-b751-9684b62cc9a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mrs. Norris'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "VdsOQ4GrInJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets tqdm"
      ],
      "metadata": {
        "id": "dHLfJYDiGlrZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the ground truth data from QAEval\n",
        "from datasets import Dataset\n",
        "#eval_dataset = Dataset.from_csv(\"QAEval.csv\", encoding='latin1', sep = ';')\n",
        "eval_dataset = Dataset.from_csv(\"QAEval.csv\")\n",
        "eval_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J92Y5CDNHdTD",
        "outputId": "0c652516-4e3b-45c2-ca7a-627d5211a88f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'ground_truth'],\n",
              "    num_rows: 141\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The QAEval.csv containing the ground truth data is created in the [EvalDataGenerator](https://colab.research.google.com/github/ash-rulz/TextMining/blob/main/EvalDataGenerator.ipynbhttps://) notebook."
      ],
      "metadata": {
        "id": "gJyif3HTu9CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Format the data into the RAGAS structure\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "def create_ragas_dataset(rag_chain, eval_dataset):\n",
        "  rag_dataset = []\n",
        "  for row in tqdm(eval_dataset):\n",
        "    answer = rag_chain.invoke({\"question\" : row[\"question\"]})\n",
        "    rag_dataset.append(\n",
        "        {\"question\" : row[\"question\"],\n",
        "         \"answer\" : answer[\"response\"],\n",
        "         \"contexts\" : [context.page_content for context in answer[\"context\"]],\n",
        "         \"ground_truths\" : [row[\"ground_truth\"]]\n",
        "         }\n",
        "    )\n",
        "  rag_df = pd.DataFrame(rag_dataset)\n",
        "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
        "  return rag_eval_dataset\n",
        "\n",
        "basic_qa_ragas_dataset = create_ragas_dataset(retrieval_augmented_qa_chain, eval_dataset)\n",
        "basic_qa_ragas_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN_SpKKvJEEa",
        "outputId": "453ce9b1-aaf1-4b1d-9c81-8772ca15efee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 141/141 [16:45<00:00,  7.13s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
              "    num_rows: 141\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataset to a Parquet file\n",
        "save_path = '/content/basic_qa_ragas_dataset.parquet'\n",
        "basic_qa_ragas_dataset.to_pandas().to_parquet(save_path)"
      ],
      "metadata": {
        "id": "NnWHNaD_J9Jj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "save_path = '/content/basic_qa_ragas_dataset.parquet'\n",
        "ragas_eval_dataset =  Dataset.from_pandas(pd.read_parquet(save_path))\n",
        "ragas_eval_dataset"
      ],
      "metadata": {
        "id": "3bk9JkHDKElw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47f4d35-2433-4086-d34e-9dc0440d7f89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
              "    num_rows: 141\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U ragas openai"
      ],
      "metadata": {
        "id": "SjjPiNp1uUTv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAGAs evaluation needs OpenAI api key."
      ],
      "metadata": {
        "id": "VQlUVZ9cuYMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import getpass\n",
        "\n",
        "open_ai_key = getpass.getpass('Enter your OPENAI API Key')\n",
        "os.environ['OPENAI_API_KEY'] = open_ai_key"
      ],
      "metadata": {
        "id": "dJsJnwiSuXj3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    context_relevancy,\n",
        "    answer_correctness,\n",
        "    answer_similarity\n",
        ")\n",
        "from ragas import evaluate\n",
        "eval_result = evaluate(\n",
        "  ragas_eval_dataset,\n",
        "  metrics=[\n",
        "      context_precision,\n",
        "      faithfulness,\n",
        "      answer_relevancy,\n",
        "      context_recall,\n",
        "      context_relevancy,\n",
        "      answer_correctness,\n",
        "      answer_similarity\n",
        "  ],\n",
        ")\n",
        "eval_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycHNrPRUyZZR",
        "outputId": "803ba2b8-37bf-4f72-98b1-3a2cc5df702b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [context_precision]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:13<00:00, 13.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [faithfulness]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:57<00:00, 17.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [answer_relevancy]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:41<00:00, 16.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [context_recall]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:11<00:00, 13.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [context_relevancy]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:04<00:00, 12.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [answer_correctness]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [01:34<00:00,  9.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [answer_similarity]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_precision': 0.2996, 'faithfulness': 0.4255, 'answer_relevancy': 0.6323, 'context_recall': 0.6390, 'context_relevancy': 0.1007, 'answer_correctness': 0.4832, 'answer_similarity': 0.8691}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tHliJN-94-Fi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}